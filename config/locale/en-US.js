module.exports = {

    // Contact us
    contact_us:                             "Contact Us",
    learn_more:                             "To learn more about SparkAPI",
    enter_email:                            "Enter your work email address",

    // Classes of tools

    // annotation tool page
    get_start_now:                          "Get Start Now",
    time_per_annotation:                    "Time per annotation",
    cost_per_annotation:                    "Cost per annotation",
    shape_perception:                       "Shape perception",
    spatial_perception:                     "Spatial perception",

    use_case:                               "USE CASES",

    moderate:                               "Moderate",
    expensive:                              "Expensive",
    most_expensive:                         "Most Expensive",
    lowest:                                 "Lowest",
    highest:                                "Highest",
    high:                                   "High",
    lease_expensive:                        "Least Expensive",
    absent:                                 "Absent",
    present:                                "Present",

    supports_100s_of_classes:               "Supports 100s of classes",
    supports_100s_of_classes_description:   "Well-designed tools to support large number of classes of interest.",
    guaranteed_precision:                   "Guaranteed Precision",
    guaranteed_precision_description:       "Consensus models to verify each of the annotations by multiple users for label accuracy & annotation perfection.",
    guaranteed_recall:                      "Guaranteed Recall",
    guaranteed_recall_description:          "Recursive checks from multiple users to detect all the objects of interest in the frame.",

    all_kinds_of_complexities:              "ALL KINDS OF COMPLEXITIES ARE HANDLED",

    multiple_shapes:                        "Multiple Shapes",
    multiple_shapes_description:            "All shape annotations on single media",

    lots_of_classes:                        "Lots of Classes",
    lots_of_classes_description:            "Support for hundreds of classes",

    pixel_perfect_annotation:               "Pixel Perfect Annotation",
    pixel_perfect_annotation_description:   "Guaranteed highly accurate results",

    country_specific:                       "Country Specific",
    country_specific_description:           "Contexual information from the data",

    why_sparkapi:                           "WHY SparkAPI",

    assured_quality:                        "Assured Quality",
    assured_quality_description:            "Guaranteed accuracy. We know youâ€™d have it no other way.",

    fully_managed:                          "Fully Managed",
    fully_managed_description:              "Use our API to get responses within minutes.",

    faster_at_scale:                        "Faster at Scale",
    faster_at_scale_description:            "We do the heavy lifting so that you can relax.",

    // Bounding box tool page
    toolsBannerTextTitle_BoundingBox:       "2D Bounding Boxes",
    toolsBannerTextDescription_BoundingBox: "For object detection and localization in images and videos",

    toolsUsecasesItemContentTitle1_BoundingBox:         "Object localization for Self-driving cars",
    toolsUsecasesItemContentDescription1_BoundingBox:   "Extensively used to train autonomous driving perception models for pedestrians, traffic signs, lane obstacles, etc.",
    toolsUsecasesItemImg1_BoundingBox:         "/image/tools/usecases/BoundingBox_SelfDrivingCars.jpg",

    toolsUsecasesItemContentTitle2_BoundingBox:         "Object Detection for e-commerce",
    toolsUsecasesItemContentDescription2_BoundingBox:   "Used to train visual search machine learning models for recognition of various fashion accessories and furniture.",
    toolsUsecasesItemImg2_BoundingBox:         "/image/tools/usecases/BoundingBox_Ecommerce.jpg",

    toolsUsecasesItemContentTitle3_BoundingBox:         "Damage detection for Insurance",
    toolsUsecasesItemContentDescription3_BoundingBox:   "Identification of car damage, roof damage or safety parameters from live world images to train machine learning models that detect the degree of damage for insurance claims.",
    toolsUsecasesItemImg3_BoundingBox:         "/image/tools/usecases/BoundingBox_Insurance.jpg",

    toolsUsecasesItemContentTitle4_BoundingBox:         "Drone and Robot training",
    toolsUsecasesItemContentDescription4_BoundingBox:   "Labelled images for training smart surveillance drones and robots to identify a variety of objects.",
    toolsUsecasesItemImg4_BoundingBox:         "/image/tools/usecases/BoundingBox_DroneandRobot.jpg",

    // Polygon tool page
    toolsBannerTextTitle_Polygon:       "Polygon Annotation",
    toolsBannerTextDescription_Polygon: "For precise object shape detection and localization in images and videos",

    toolsUsecasesItemContentTitle1_Polygon:         "Object localization from satellite and drone images",
    toolsUsecasesItemContentDescription1_Polygon:   "Used to best approximate the shape of objects captured from distant cameras.",

    toolsUsecasesItemContentTitle2_Polygon:         "Detection of irregular shapes",
    toolsUsecasesItemContentDescription2_Polygon:   "Good for detection models for logos, street sign boards, facial and pose features in sports analytics, etc.",

    toolsUsecasesItemContentTitle3_Polygon:         "Coarse Semantic Segmentation",
    toolsUsecasesItemContentDescription3_Polygon:   "Coarse segmentation for weak supervision of your models to improve your model accuracy.",

    // Segmentation tool page
    toolsBannerTextTitle_Segmentation:       "Semantic Segmentation",
    toolsBannerTextDescription_Segmentation: "For pixel level scene understanding",

    toolsUsecasesItemContentTitle1_Segmentation:         "Instance segmentation for feature detection",
    toolsUsecasesItemContentDescription1_Segmentation:   "Used for training perception models in non-environmental objects of interest.",

    toolsUsecasesItemContentTitle2_Segmentation:         "Full pixel semantic segmentation",
    toolsUsecasesItemContentDescription2_Segmentation:   "High utility in autonomous vehicles and safety surveillance cameras where information of every pixel is critical and may influence the accuracy of the perception model.",

    toolsUsecasesItemContentTitle3_Segmentation:         "Panoptic segmentation",
    toolsUsecasesItemContentDescription3_Segmentation:   "Used to individually segment objects of the same class by assigning instance unique IDs to each object.",

    // Landmark tool page
    toolsBannerTextTitle_Landmark:       "Landmark Annotation",
    toolsBannerTextDescription_Landmark: "Plotting a sequence of points to determine shape variations of minute and large objects",

    toolsUsecasesItemContentTitle1_Landmark:         "Point annotation for satellite imagery",
    toolsUsecasesItemContentDescription1_Landmark:   "Used to detect and count minute objects like houses or trees in a area, cars in parking lots, etc.",

    toolsUsecasesItemContentTitle2_Landmark:         "Landmarking for pose-point annotations",
    toolsUsecasesItemContentDescription2_Landmark:   "Detect poses of sports players for sports analytics, facial features for face recognition, prediction of pedestrians motion for autonomous vehicles.",

    // Line tool page
    toolsBannerTextTitle_Line:       "Line Annotation",
    toolsBannerTextDescription_Line: "Define pixel coordinate and polylines for precision training Autonomous Driving model",

    toolsUsecasesItemContentTitle1_Line:         "Lane detection for self-driving cars.",
    toolsUsecasesItemContentDescription1_Line:   "Well-defined different kinds of lanes for ego car, bicycle, opposite direction traffic, divergence etc.",

    // 3D Cuboid tool page
    toolsBannerTextTitle_3DCuboid:       "3D Cuboids Annotation",
    toolsBannerTextDescription_3DCuboid: "For 3D perception from 2D images and videos",

    toolsUsecasesItemContentTitle1_3DCuboid:         "Camera based perception in autonomous vehicles",
    toolsUsecasesItemContentDescription1_3DCuboid:   "Used to train computer vision models for spatial cognition from 2D images or videos. Relative distance of each mobile object from the ego car and vanishing point can be measured.",

    toolsUsecasesItemContentTitle2_3DCuboid:         "In-doors spatial distribution of objects",
    toolsUsecasesItemContentDescription2_3DCuboid:   "Used to build 3D simulated worlds from 2D information captured by cameras.",


}